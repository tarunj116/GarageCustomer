"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = exports.getNextIdGroup = exports.findNextItemIndex = void 0;

var _shared = require("@rpldy/shared");

var _processBatchItems = _interopRequireDefault(require("./processBatchItems"));

var _batchHelpers = require("./batchHelpers");

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

const getIsItemInActiveRequest = (queue, itemId) => {
  return !!~queue.getState().activeIds // $FlowFixMe - no flat
  .flat().indexOf(itemId);
};

const getIsItemReady = item => item.state === _shared.FILE_STATES.ADDED;

const findNextItemIndex = queue => {
  const state = queue.getState(),
        itemQueue = state.itemQueue,
        items = state.items;
  let index = 0,
      nextId = itemQueue[index]; //find item that isnt already in an active request and belongs to a "ready" batch

  while (nextId && (getIsItemInActiveRequest(queue, nextId) || !(0, _batchHelpers.getIsItemBatchReady)(queue, nextId) || !getIsItemReady(items[nextId]))) {
    index += 1;
    nextId = itemQueue[index];
  }

  return nextId ? index : -1;
};

exports.findNextItemIndex = findNextItemIndex;

const getNextIdGroup = queue => {
  const itemQueue = queue.getState().itemQueue;
  const nextItemIndex = findNextItemIndex(queue);
  let nextId = itemQueue[nextItemIndex],
      nextGroup;

  if (nextId) {
    const batchData = (0, _batchHelpers.getBatchDataFromItemId)(queue, nextId);
    const batchId = batchData.batch.id,
          groupMax = batchData.batchOptions.maxGroupSize || 0;

    if (batchData.batchOptions.grouped && groupMax > 1) {
      nextGroup = [];
      let nextBelongsToSameBatch = true; //dont group files from different batches

      while (nextGroup.length < groupMax && nextBelongsToSameBatch) {
        nextGroup.push(nextId);
        nextId = itemQueue[nextItemIndex + nextGroup.length];
        nextBelongsToSameBatch = nextId && (0, _batchHelpers.isItemBelongsToBatch)(queue, nextId, batchId);
      }
    } else {
      nextGroup = [nextId];
    }
  }

  return nextGroup;
};

exports.getNextIdGroup = getNextIdGroup;

const processNext = queue => {
  const ids = getNextIdGroup(queue);
  let resultP = Promise.resolve();

  if (ids) {
    const currentCount = queue.getCurrentActiveCount(),
          {
      concurrent = 0,
      maxConcurrent = 0
    } = queue.getOptions();

    if (!currentCount || concurrent && currentCount < maxConcurrent) {
      _shared.logger.debugLog("uploader.processor: Processing next upload - ", {
        ids,
        state: queue.getState(),
        currentCount
      });

      let cancelled = false;
      let newBatchP = Promise.resolve(false);

      if ((0, _batchHelpers.isNewBatchStarting)(queue, ids[0])) {
        newBatchP = (0, _batchHelpers.loadNewBatchForItem)(queue, ids[0]).then(allowBatch => {
          cancelled = !allowBatch;

          if (cancelled) {
            (0, _batchHelpers.cancelBatchForItem)(queue, ids[0]);
            processNext(queue);
          }

          return cancelled;
        });
      }

      resultP = newBatchP.then(cancelled => {
        if (!cancelled) {
          (0, _processBatchItems.default)(queue, ids, processNext);
        }
      });
    }
  }

  return resultP;
};

var _default = processNext;
exports.default = _default;